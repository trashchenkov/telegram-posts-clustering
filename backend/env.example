# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false

# CORS Origins (comma separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# LLM Provider (openai, anthropic, gemini, ollama, none)
LLM_PROVIDER=none

# API Keys (uncomment and set the one you want to use)
# OPENAI_API_KEY=your_openai_api_key_here
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# GEMINI_API_KEY=your_gemini_api_key_here

# Model Configuration
OPENAI_MODEL=gpt-4.1-nano-2025-04-14
ANTHROPIC_MODEL=claude-3-haiku-20240307
GEMINI_MODEL=gemini-pro
OLLAMA_MODEL=llama2
OLLAMA_BASE_URL=http://localhost:11434

# Clustering Configuration
MAX_CONCURRENT_REQUESTS=5
CLUSTERING_TIMEOUT=30
MIN_CLUSTERS=2
MAX_CLUSTERS=8
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Telegram Parsing
POSTS_LIMIT_PER_CHANNEL=50
HOURS_BACK=24 