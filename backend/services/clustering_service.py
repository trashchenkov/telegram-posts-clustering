from typing import List, Optional, Dict, Any
import asyncio
import logging
import random
import json
from datetime import datetime
import numpy as np
from sklearn.cluster import DBSCAN, KMeans
from sklearn.metrics import silhouette_score
from sentence_transformers import SentenceTransformer
import openai

from models.post import RawPost, Post
from config.settings import settings

logger = logging.getLogger(__name__)

class ClusteringService:
    def __init__(self):
        self.embedding_model = None
        self.openai_client = None
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è keyword-based –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (fallback)
        self.keyword_clusters = {
            "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç": ["ai", "–∏–∏", "–Ω–µ–π—Ä–æ", "ml", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "gpt", "llm", "openai", "anthropic", "claude"],
            "–í–∞–∫–∞–Ω—Å–∏–∏": ["—Ä–∞–±–æ—Ç–∞", "–≤–∞–∫–∞–Ω—Å–∏—è", "hiring", "job", "developer", "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫"],
            "–ù–æ–≤–æ—Å—Ç–∏": ["–Ω–æ–≤–æ—Å—Ç–∏", "news", "–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "—Ä–µ–ª–∏–∑", "–∞–Ω–æ–Ω—Å"],
            "–ú–µ–º—ã": ["–º–µ–º", "üòÇ", "ü§£", "funny", "—é–º–æ—Ä", "–ø—Ä–∏–∫–æ–ª"],
            "–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã": ["–∫—Ä–∏–ø—Ç–æ", "bitcoin", "–±–ª–æ–∫—á–µ–π–Ω", "ethereum", "btc", "eth"],
            "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞": ["–∫–æ–¥", "–ø—Ä–æ–≥—Ä–∞–º–º", "—Ä–∞–∑—Ä–∞–±–æ—Ç", "python", "javascript", "github"],
            "–ë–∏–∑–Ω–µ—Å": ["—Å—Ç–∞—Ä—Ç–∞–ø", "–±–∏–∑–Ω–µ—Å", "–∏–Ω–≤–µ—Å—Ç", "–¥–µ–Ω—å–≥–∏", "—Ñ–∏–Ω–∞–Ω—Å—ã"],
            "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ": ["–∫—É—Ä—Å", "–æ–±—É—á–µ–Ω–∏–µ", "—Ç—É—Ç–æ—Ä–∏–∞–ª", "—É—Ä–æ–∫", "–ª–µ–∫—Ü–∏—è"],
            "–°–æ–±—ã—Ç–∏—è": ["–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è", "–º–∏—Ç–∞–ø", "—Å–æ–±—ã—Ç–∏–µ", "–≤—Å—Ç—Ä–µ—á–∞", "–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ"]
        }
        
        self._initialize_models()

    def _initialize_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embedding –º–æ–¥–µ–ª–∏
            logger.info("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è embeddings...")
            self.embedding_model = SentenceTransformer(settings.embedding_model)
            logger.info("‚úÖ Embedding –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
            if settings.openai_api_key:
                self.openai_client = openai.OpenAI(api_key=settings.openai_api_key)
                logger.info("‚úÖ OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            else:
                logger.warning("‚ö†Ô∏è OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è fallback")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π: {e}")

    def _get_embeddings(self, texts: List[str]) -> np.ndarray:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ embeddings –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤"""
        if not self.embedding_model:
            raise Exception("Embedding –º–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–∫—Å—Ç—ã
        valid_texts = [text if text else "–ü–æ—Å—Ç –±–µ–∑ —Ç–µ–∫—Å—Ç–∞" for text in texts]
        
        logger.info(f"üîÑ –ü–æ–ª—É—á–∞–µ–º embeddings –¥–ª—è {len(valid_texts)} —Ç–µ–∫—Å—Ç–æ–≤...")
        embeddings = self.embedding_model.encode(valid_texts)
        logger.info(f"‚úÖ Embeddings –ø–æ–ª—É—á–µ–Ω—ã: {embeddings.shape}")
        
        return embeddings

    def _find_optimal_clusters(self, embeddings: np.ndarray, min_clusters: int = None, max_clusters: int = None) -> int:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        if min_clusters is None:
            min_clusters = settings.min_clusters
        if max_clusters is None:
            max_clusters = settings.max_clusters
            
        if len(embeddings) < min_clusters:
            return 1
        
        best_score = -1
        best_k = min_clusters
        
        for k in range(min_clusters, min(max_clusters + 1, len(embeddings))):
            try:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                cluster_labels = kmeans.fit_predict(embeddings)
                
                if len(set(cluster_labels)) > 1:  # –ë–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
                    score = silhouette_score(embeddings, cluster_labels)
                    if score > best_score:
                        best_score = score
                        best_k = k
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ k={k}: {e}")
                continue
        
        logger.info(f"üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {best_k} (score: {best_score:.3f})")
        return best_k

    def _cluster_embeddings(self, embeddings: np.ndarray) -> np.ndarray:
        """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è embeddings"""
        if len(embeddings) < 2:
            return np.array([0] * len(embeddings))
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        optimal_k = self._find_optimal_clusters(embeddings)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
        if optimal_k == 1:
            return np.array([0] * len(embeddings))
        
        kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(embeddings)
        
        logger.info(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {optimal_k} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        return cluster_labels

    def _get_representative_posts(self, posts: List[RawPost], cluster_labels: np.ndarray, embeddings: np.ndarray) -> Dict[int, List[str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        cluster_representatives = {}
        
        for cluster_id in set(cluster_labels):
            cluster_mask = cluster_labels == cluster_id
            cluster_posts = [posts[i] for i in range(len(posts)) if cluster_mask[i]]
            cluster_embeddings = embeddings[cluster_mask]
            
            # –ë–µ—Ä–µ–º –¥–æ 3 —Å–∞–º—ã—Ö —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
            if len(cluster_posts) <= 3:
                representatives = [post.post_text or "–ü–æ—Å—Ç –±–µ–∑ —Ç–µ–∫—Å—Ç–∞" for post in cluster_posts]
            else:
                # –ù–∞—Ö–æ–¥–∏–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥ –∫–ª–∞—Å—Ç–µ—Ä–∞
                centroid = np.mean(cluster_embeddings, axis=0)
                
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å—Ç—ã –±–ª–∏–∂–∞–π—à–∏–µ –∫ —Ü–µ–Ω—Ç—Ä–æ–∏–¥—É
                distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)
                closest_indices = np.argsort(distances)[:3]
                
                representatives = [cluster_posts[i].post_text or "–ü–æ—Å—Ç –±–µ–∑ —Ç–µ–∫—Å—Ç–∞" for i in closest_indices]
            
            cluster_representatives[cluster_id] = representatives
        
        return cluster_representatives

    async def _generate_cluster_names_with_llm(self, cluster_representatives: Dict[int, List[str]]) -> Dict[int, str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM"""
        if not self.openai_client:
            logger.warning("‚ö†Ô∏è OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback –Ω–∞–∑–≤–∞–Ω–∏—è")
            return {cluster_id: f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}" for cluster_id in cluster_representatives.keys()}
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å—Ä–∞–∑—É
            prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≥—Ä—É–ø–ø—ã –ø–æ—Å—Ç–æ–≤ –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤ –ø—Ä–æ AI/—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –¥–∞–π –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (2-4 —Å–ª–æ–≤–∞).

–ì—Ä—É–ø–ø—ã –ø–æ—Å—Ç–æ–≤:
"""
            
            for cluster_id, posts in cluster_representatives.items():
                prompt += f"\n–ì—Ä—É–ø–ø–∞ {cluster_id + 1}:\n"
                for i, post in enumerate(posts, 1):
                    prompt += f"{i}. {post[:200]}...\n"
            
            prompt += """
–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{
  "0": "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã 1",
  "1": "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã 2",
  ...
}

–ù–∞–∑–≤–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –æ—Ç—Ä–∞–∂–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é —Ç–µ–º—É –≥—Ä—É–ø–ø—ã."""

            logger.info("ü§ñ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —É LLM...")
            
            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model=settings.openai_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
            try:
                cluster_names = json.loads(result_text)
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–∏ –≤ int
                cluster_names = {int(k): v for k, v in cluster_names.items()}
                logger.info(f"‚úÖ LLM —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –Ω–∞–∑–≤–∞–Ω–∏—è: {cluster_names}")
                return cluster_names
            except json.JSONDecodeError:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç LLM: {result_text}")
                return {cluster_id: f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}" for cluster_id in cluster_representatives.keys()}
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {e}")
            return {cluster_id: f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}" for cluster_id in cluster_representatives.keys()}

    def _classify_post_by_keywords(self, post_text: Optional[str]) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (fallback)"""
        if not post_text:
            return "–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞"
        
        text_lower = post_text.lower()
        
        # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        for cluster_name, keywords in self.keyword_clusters.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return cluster_name
        
        return "–ù–µ–∫–∞—Ç–µ–≥–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ"

    async def cluster_posts(self, raw_posts: List[RawPost]) -> List[Post]:
        """–ì–∏–±—Ä–∏–¥–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω—É—é –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é {len(raw_posts)} –ø–æ—Å—Ç–æ–≤...")
        start_time = datetime.now()
        
        if len(raw_posts) == 0:
            return []
        
        # –ï—Å–ª–∏ –ø–æ—Å—Ç–æ–≤ –º–∞–ª–æ –∏–ª–∏ –Ω–µ—Ç embedding –º–æ–¥–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º keyword-based
        if len(raw_posts) < 3 or not self.embedding_model:
            logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º keyword-based –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é (–º–∞–ª–æ –ø–æ—Å—Ç–æ–≤ –∏–ª–∏ –Ω–µ—Ç –º–æ–¥–µ–ª–∏)")
            clustered_posts = []
            for post in raw_posts:
                cluster_name = self._classify_post_by_keywords(post.post_text)
                clustered_post = Post(**post.dict(), cluster_name=cluster_name)
                clustered_posts.append(clustered_post)
            return clustered_posts
        
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º embeddings
            texts = [post.post_text or "–ü–æ—Å—Ç –±–µ–∑ —Ç–µ–∫—Å—Ç–∞" for post in raw_posts]
            embeddings = self._get_embeddings(texts)
            
            # 2. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º
            cluster_labels = self._cluster_embeddings(embeddings)
            
            # 3. –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã–µ –ø–æ—Å—Ç—ã
            cluster_representatives = self._get_representative_posts(raw_posts, cluster_labels, embeddings)
            
            # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM
            cluster_names = await self._generate_cluster_names_with_llm(cluster_representatives)
            
            # 5. –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –ø–æ—Å—Ç–∞–º
            clustered_posts = []
            for i, post in enumerate(raw_posts):
                cluster_id = cluster_labels[i]
                cluster_name = cluster_names.get(cluster_id, f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}")
                clustered_post = Post(**post.dict(), cluster_name=cluster_name)
                clustered_posts.append(clustered_post)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"‚úÖ –ì–∏–±—Ä–∏–¥–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f} —Å–µ–∫—É–Ω–¥")
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(set(cluster_labels))}")
            
            return clustered_posts
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –≥–∏–±—Ä–∏–¥–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ keyword-based –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
            
            # Fallback –Ω–∞ keyword-based
            clustered_posts = []
            for post in raw_posts:
                cluster_name = self._classify_post_by_keywords(post.post_text)
                clustered_post = Post(**post.dict(), cluster_name=cluster_name)
                clustered_posts.append(clustered_post)
            
            return clustered_posts

    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
        return True  # –í—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω –±–ª–∞–≥–æ–¥–∞—Ä—è fallback

    def get_provider_info(self) -> dict:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–µ"""
        has_embeddings = self.embedding_model is not None
        has_openai = self.openai_client is not None
        
        if has_embeddings and has_openai:
            provider = "hybrid (embeddings + LLM)"
        elif has_embeddings:
            provider = "embeddings only"
        else:
            provider = "keyword-based"
        
        return {
            "provider": provider,
            "available": True,
            "embedding_model": "all-MiniLM-L6-v2" if has_embeddings else None,
            "llm_model": settings.openai_model if has_openai else None
        } 