from datetime import datetime, timedelta, timezone
from typing import List, Optional
import logging
import asyncio
import random
from concurrent.futures import ThreadPoolExecutor
import re
import os
import httpx
from bs4 import BeautifulSoup

from models.post import RawPost

logger = logging.getLogger(__name__)

class TelegramParser:
    def __init__(self, max_workers: int = 5):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    def _extract_formatted_text(self, text_elem) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –±–∞–∑–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if not text_elem:
            return None
            
        # –ó–∞–º–µ–Ω—è–µ–º <br> –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        for br in text_elem.find_all('br'):
            br.replace_with('\n')
        
        # –ó–∞–º–µ–Ω—è–µ–º –±–ª–æ—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        for block in text_elem.find_all(['div', 'p']):
            if block.get_text(strip=True):  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
                block.insert_after('\n')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç
        text = text_elem.get_text()
        
        # –û—á–∏—â–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # –£–±–∏—Ä–∞–µ–º —Ç—Ä–æ–π–Ω—ã–µ+ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'[ \t]+', ' ', text)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = text.strip()
        
        return text if text else None
    
    def _clean_snscrape_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç snscrape"""
        if not text:
            return None
            
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–∞–±—É–ª—è—Ü–∏–∏
        text = re.sub(r'[ \t]+', ' ', text)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\r\n', '\n', text)
        text = re.sub(r'\r', '\n', text)
        
        # –£–±–∏—Ä–∞–µ–º —Ç—Ä–æ–π–Ω—ã–µ+ –ø–µ—Ä–µ–Ω–æ—Å—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º –¥–≤–æ–π–Ω—ã–µ
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        lines = [line.strip() for line in text.split('\n')]
        text = '\n'.join(lines)
        
        return text.strip() if text.strip() else None
    
    async def _parse_channel_with_http(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ HTTP –∑–∞–ø—Ä–æ—Å—ã –∫ t.me"""
        posts = []
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º UTC timezone –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours_back)
        
        try:
            url = f"https://t.me/s/{channel}"
            logger.info(f"üåê –ü–æ–ø—ã—Ç–∫–∞ HTTP –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ {channel}: {url}")
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(url)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # –ò—â–µ–º –ø–æ—Å—Ç—ã –≤ HTML
                post_elements = soup.find_all('div', class_='tgme_widget_message')
                
                post_count = 0
                for element in post_elements[:limit]:
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –ø–æ—Å—Ç–∞
                        post_link_elem = element.find('a', class_='tgme_widget_message_date')
                        if not post_link_elem:
                            continue
                            
                        post_link = post_link_elem.get('href', '')
                        post_id = post_link.split('/')[-1] if post_link else str(post_count)
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º—è
                        time_elem = element.find('time')
                        if time_elem and time_elem.get('datetime'):
                            post_time = datetime.fromisoformat(time_elem['datetime'].replace('Z', '+00:00'))
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                            if post_time < cutoff_time:
                                continue
                        else:
                            # –ï—Å–ª–∏ –≤—Ä–µ–º—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –º–∏–Ω—É—Å —Å–ª—É—á–∞–π–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
                            post_time = datetime.now(timezone.utc) - timedelta(minutes=random.randint(0, hours_back * 60))
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                        text_elem = element.find('div', class_='tgme_widget_message_text')
                        post_text = self._extract_formatted_text(text_elem)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞
                        has_media = bool(element.find('a', class_='tgme_widget_message_photo_wrap') or 
                                       element.find('video') or 
                                       element.find('div', class_='tgme_widget_message_video'))
                        
                        if post_text or has_media:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
                            post = RawPost(
                                id=f"{channel}_http_{post_id}_{int(post_time.timestamp())}",
                                channel_name=channel,
                                publication_datetime=post_time.isoformat(),
                                post_link=post_link or f"https://t.me/{channel}/{post_id}",
                                post_text=post_text,
                                has_media=has_media
                            )
                            posts.append(post)
                            post_count += 1
                            
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞ –≤ –∫–∞–Ω–∞–ª–µ {channel}: {e}")
                        continue
                
                logger.info(f"‚úÖ HTTP: –Ω–∞–π–¥–µ–Ω–æ {post_count} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –≤ –∫–∞–Ω–∞–ª–µ {channel}")
                return posts
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è HTTP –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
            raise
    
    def _parse_channel_with_snscrape(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ snscrape"""
        posts = []
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º UTC timezone –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=hours_back)
        
        try:
            import snscrape.modules.telegram as snstelegram
            
            logger.info(f"üîß –ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ {channel} —á–µ—Ä–µ–∑ snscrape...")
            
            # –°–æ–∑–¥–∞–µ–º scraper –¥–ª—è –∫–∞–Ω–∞–ª–∞
            scraper = snstelegram.TelegramChannelScraper(channel)
            
            post_count = 0
            for i, item in enumerate(scraper.get_items()):
                if i >= limit:
                    logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {limit} –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}")
                    break
                    
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ item.date –∏–º–µ–µ—Ç timezone info
                item_date = item.date
                if item_date.tzinfo is None:
                    item_date = item_date.replace(tzinfo=timezone.utc)
                
                if item_date < cutoff_time:
                    logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –≥—Ä–∞–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏ {hours_back}—á –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}")
                    break
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                post_text = None
                if hasattr(item, 'content') and item.content:
                    post_text = self._clean_snscrape_text(item.content)
                elif hasattr(item, 'rawContent') and item.rawContent:
                    post_text = self._clean_snscrape_text(item.rawContent)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞
                has_media = False
                if hasattr(item, 'media') and item.media:
                    has_media = True
                elif hasattr(item, 'photo') and item.photo:
                    has_media = True
                elif hasattr(item, 'video') and item.video:
                    has_media = True
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Å—Ç
                post_link = f"https://t.me/{channel}/{item.id}" if hasattr(item, 'id') else item.url
                
                post = RawPost(
                    id=f"{channel}_snscrape_{item.id}_{int(item.date.timestamp())}",
                    channel_name=channel,
                    publication_datetime=item.date.isoformat(),
                    post_link=post_link,
                    post_text=post_text,
                    has_media=has_media
                )
                posts.append(post)
                post_count += 1
                
            logger.info(f"‚úÖ snscrape: –Ω–∞–π–¥–µ–Ω–æ {post_count} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –≤ –∫–∞–Ω–∞–ª–µ {channel}")
            return posts
            
        except ImportError as e:
            logger.error(f"‚ùå snscrape –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
            raise
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è snscrape –æ—à–∏–±–∫–∞ –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
            raise
    
    async def _parse_channel_sync(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π"""
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: HTTP –ø–∞—Ä—Å–∏–Ω–≥
        try:
            return await self._parse_channel_with_http(channel, hours_back, limit)
        except Exception as e:
            logger.warning(f"HTTP –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è {channel}: {e}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: snscrape
        try:
            return self._parse_channel_with_snscrape(channel, hours_back, limit)
        except Exception as e:
            logger.warning(f"snscrape –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è {channel}: {e}")
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        logger.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ—Å—Ç—ã –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}")
        return []
    
    async def parse_channel(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞"""
        return await self._parse_channel_sync(channel, hours_back, limit)
    
    async def parse_channels(self, channels: List[str], hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞–Ω–∞–ª–æ–≤"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ {len(channels)} –∫–∞–Ω–∞–ª–æ–≤...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [
            self.parse_channel(channel, hours_back, limit) 
            for channel in channels
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã
        all_posts = []
        successful_channels = 0
        failed_channels = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞–Ω–∞–ª–∞ {channels[i]}: {str(result)}")
                failed_channels += 1
            elif len(result) == 0:
                logger.warning(f"‚ö†Ô∏è –ö–∞–Ω–∞–ª {channels[i]} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ—Å—Ç–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥")
                failed_channels += 1
            else:
                all_posts.extend(result)
                successful_channels += 1
                logger.info(f"‚úÖ –ö–∞–Ω–∞–ª {channels[i]}: –ø–æ–ª—É—á–µ–Ω–æ {len(result)} –ø–æ—Å—Ç–æ–≤")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        all_posts.sort(
            key=lambda x: datetime.fromisoformat(x.publication_datetime), 
            reverse=True
        )
        
        logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(all_posts)} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤")
        logger.info(f"üéØ –£—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {successful_channels}/{len(channels)}")
        logger.info(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {failed_channels}/{len(channels)}")
        
        return all_posts
    
    def __del__(self):
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True) 