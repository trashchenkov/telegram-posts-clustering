from datetime import datetime, timedelta
from typing import List, Optional
import logging
import asyncio
import random
from concurrent.futures import ThreadPoolExecutor
import re
import os
import httpx
from bs4 import BeautifulSoup

from models.post import RawPost

logger = logging.getLogger(__name__)

class TelegramParser:
    def __init__(self, max_workers: int = 5):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        
        # Mock –¥–∞–Ω–Ω—ã–µ –¥–ª—è fallback
        self.mock_texts = [
            "üöÄ –ù–æ–≤—ã–π —Ä–µ–ª–∏–∑ GPT-5!\n\n–†–µ–≤–æ–ª—é—Ü–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –ò–ò –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è. –û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:\n‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —É–≤–µ–ª–∏—á–µ–Ω–∞ –≤ 3 —Ä–∞–∑–∞\n‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ 200+ —è–∑—ã–∫–æ–≤\n‚Ä¢ –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è",
            "üìä –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç\n\nBitcoin –¥–æ—Å—Ç–∏–≥ –Ω–æ–≤–æ–≥–æ –º–∞–∫—Å–∏–º—É–º–∞ $75,000!\n\n–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–æ—Å—Ç–∞:\n- –ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏\n- –†–µ–≥—É–ª—è—Ç–∏–≤–Ω–∞—è —è—Å–Ω–æ—Å—Ç—å\n- –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è",
            "üíº –û—Ç–∫—Ä—ã—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏—è Senior Python Developer\n\n–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n‚Ä¢ Python 3.9+\n‚Ä¢ FastAPI, Django\n‚Ä¢ Docker, Kubernetes\n‚Ä¢ –û–ø—ã—Ç —Å ML/AI\n\n–ó–∞—Ä–ø–ª–∞—Ç–∞: –æ—Ç 300k —Ä—É–±",
            "üî¨ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ–∫–∞–∑–∞–ª–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ ML\n\n–£—á–µ–Ω—ã–µ –∏–∑ MIT —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π:\n\n‚úÖ –û–±—É—á–∞–µ—Ç—Å—è –≤ 10 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ\n‚úÖ –¢—Ä–µ–±—É–µ—Ç –Ω–∞ 50% –º–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö\n‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à—É—é —Ç–æ—á–Ω–æ—Å—Ç—å",
            "üòÇ –ú–µ–º –¥–Ω—è: –∫–æ–≥–¥–∞ –∫–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞\n\n[–ö–∞—Ä—Ç–∏–Ω–∫–∞ —Å —É–¥–∏–≤–ª–µ–Ω–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–º]\n\n‚Äî –≠—Ç–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ!\n‚Äî –ù–æ —Ñ–∞–∫—Ç –æ—Å—Ç–∞–µ—Ç—Å—è —Ñ–∞–∫—Ç–æ–º...",
            "üéØ –°—Ç–∞—Ä—Ç–∞–ø –ø—Ä–∏–≤–ª–µ–∫ $50M –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π\n\nAI-–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –ø–æ–ª—É—á–∏–ª–∞ —Å–µ—Ä–∏—é B.\n\n–ò–Ω–≤–µ—Å—Ç–æ—Ä—ã:\n‚Ä¢ Sequoia Capital\n‚Ä¢ Andreessen Horowitz\n‚Ä¢ Y Combinator",
            "üìö –ù–æ–≤—ã–π –∫—É—Ä—Å –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –æ—Ç Stanford\n\nCS229: Machine Learning\n\n–ß—Ç–æ –∏–∑—É—á–∏–º:\nüîπ Supervised Learning\nüîπ Unsupervised Learning\nüîπ Deep Learning\nüîπ Reinforcement Learning\n\n–°—Ç–∞—Ä—Ç: 15 —Ñ–µ–≤—Ä–∞–ª—è",
            "‚ö° –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Telegram\n\n–î–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤:\n\nüÜï Bot API 7.0\nüÜï Webhook —É–ª—É—á—à–µ–Ω–∏—è\nüÜï –ù–æ–≤—ã–µ —Ç–∏–ø—ã —Å–æ–æ–±—â–µ–Ω–∏–π\nüÜï –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞",
            "üåü –ò–Ω—Ç–µ—Ä–≤—å—é —Å –æ—Å–Ω–æ–≤–∞—Ç–µ–ª–µ–º —É—Å–ø–µ—à–Ω–æ–≥–æ AI —Å—Ç–∞—Ä—Ç–∞–ø–∞\n\n\"–ì–ª–∞–≤–Ω–æ–µ ‚Äî –Ω–µ –±–æ—è—Ç—å—Å—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å\"\n\n–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:\n‚Ä¢ –í–∞–∂–Ω–æ—Å—Ç—å –∫–æ–º–∞–Ω–¥—ã\n‚Ä¢ –§–æ–∫—É—Å –Ω–∞ –ø—Ä–æ–±–ª–µ–º–µ –∫–ª–∏–µ–Ω—Ç–∞\n‚Ä¢ –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ",
            "üîß –¢—É—Ç–æ—Ä–∏–∞–ª: –∫–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å CI/CD –¥–ª—è Python –ø—Ä–æ–µ–∫—Ç–æ–≤\n\n–®–∞–≥ –∑–∞ —à–∞–≥–æ–º:\n\n1Ô∏è‚É£ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GitHub Actions\n2Ô∏è‚É£ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤\n3Ô∏è‚É£ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–µ–ø–ª–æ–π\n4Ô∏è‚É£ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–ª–µ—Ä—Ç—ã"
        ]
    
    def _extract_formatted_text(self, text_elem) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –±–∞–∑–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if not text_elem:
            return None
            
        # –ó–∞–º–µ–Ω—è–µ–º <br> –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        for br in text_elem.find_all('br'):
            br.replace_with('\n')
        
        # –ó–∞–º–µ–Ω—è–µ–º –±–ª–æ—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        for block in text_elem.find_all(['div', 'p']):
            if block.get_text(strip=True):  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
                block.insert_after('\n')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç
        text = text_elem.get_text()
        
        # –û—á–∏—â–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)  # –£–±–∏—Ä–∞–µ–º —Ç—Ä–æ–π–Ω—ã–µ+ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'[ \t]+', ' ', text)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = text.strip()
        
        return text if text else None
    
    def _clean_snscrape_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç snscrape"""
        if not text:
            return None
            
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–∞–±—É–ª—è—Ü–∏–∏
        text = re.sub(r'[ \t]+', ' ', text)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\r\n', '\n', text)
        text = re.sub(r'\r', '\n', text)
        
        # –£–±–∏—Ä–∞–µ–º —Ç—Ä–æ–π–Ω—ã–µ+ –ø–µ—Ä–µ–Ω–æ—Å—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º –¥–≤–æ–π–Ω—ã–µ
        text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        lines = [line.strip() for line in text.split('\n')]
        text = '\n'.join(lines)
        
        return text.strip() if text.strip() else None
    
    async def _parse_channel_with_http(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ HTTP –∑–∞–ø—Ä–æ—Å—ã –∫ t.me"""
        posts = []
        cutoff_time = datetime.now() - timedelta(hours=hours_back)
        
        try:
            url = f"https://t.me/s/{channel}"
            logger.info(f"üåê –ü–æ–ø—ã—Ç–∫–∞ HTTP –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ {channel}: {url}")
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(url)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # –ò—â–µ–º –ø–æ—Å—Ç—ã –≤ HTML
                post_elements = soup.find_all('div', class_='tgme_widget_message')
                
                post_count = 0
                for element in post_elements[:limit]:
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –ø–æ—Å—Ç–∞
                        post_link_elem = element.find('a', class_='tgme_widget_message_date')
                        if not post_link_elem:
                            continue
                            
                        post_link = post_link_elem.get('href', '')
                        post_id = post_link.split('/')[-1] if post_link else str(post_count)
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º—è
                        time_elem = element.find('time')
                        if time_elem and time_elem.get('datetime'):
                            post_time = datetime.fromisoformat(time_elem['datetime'].replace('Z', '+00:00'))
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                            if post_time < cutoff_time:
                                continue
                        else:
                            # –ï—Å–ª–∏ –≤—Ä–µ–º—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –º–∏–Ω—É—Å —Å–ª—É—á–∞–π–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
                            post_time = datetime.now() - timedelta(minutes=random.randint(0, hours_back * 60))
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                        text_elem = element.find('div', class_='tgme_widget_message_text')
                        post_text = self._extract_formatted_text(text_elem)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞
                        has_media = bool(element.find('a', class_='tgme_widget_message_photo_wrap') or 
                                       element.find('video') or 
                                       element.find('div', class_='tgme_widget_message_video'))
                        
                        if post_text or has_media:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
                            post = RawPost(
                                id=f"{channel}_http_{post_id}_{int(post_time.timestamp())}",
                                channel_name=channel,
                                publication_datetime=post_time.isoformat(),
                                post_link=post_link or f"https://t.me/{channel}/{post_id}",
                                post_text=post_text,
                                has_media=has_media
                            )
                            posts.append(post)
                            post_count += 1
                            
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞ –≤ –∫–∞–Ω–∞–ª–µ {channel}: {e}")
                        continue
                
                logger.info(f"‚úÖ HTTP: –Ω–∞–π–¥–µ–Ω–æ {post_count} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –≤ –∫–∞–Ω–∞–ª–µ {channel}")
                return posts
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è HTTP –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
            raise
    
    def _parse_channel_with_snscrape(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ snscrape"""
        posts = []
        cutoff_time = datetime.now() - timedelta(hours=hours_back)
        
        try:
            import snscrape.modules.telegram as snstelegram
            
            logger.info(f"üîß –ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ {channel} —á–µ—Ä–µ–∑ snscrape...")
            
            # –°–æ–∑–¥–∞–µ–º scraper –¥–ª—è –∫–∞–Ω–∞–ª–∞
            scraper = snstelegram.TelegramChannelScraper(channel)
            
            post_count = 0
            for i, item in enumerate(scraper.get_items()):
                if i >= limit:
                    logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {limit} –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}")
                    break
                    
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                if item.date < cutoff_time:
                    logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –≥—Ä–∞–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏ {hours_back}—á –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}")
                    break
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                post_text = None
                if hasattr(item, 'content') and item.content:
                    post_text = self._clean_snscrape_text(item.content)
                elif hasattr(item, 'rawContent') and item.rawContent:
                    post_text = self._clean_snscrape_text(item.rawContent)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞
                has_media = False
                if hasattr(item, 'media') and item.media:
                    has_media = True
                elif hasattr(item, 'photo') and item.photo:
                    has_media = True
                elif hasattr(item, 'video') and item.video:
                    has_media = True
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Å—Ç
                post_link = f"https://t.me/{channel}/{item.id}" if hasattr(item, 'id') else item.url
                
                post = RawPost(
                    id=f"{channel}_snscrape_{item.id}_{int(item.date.timestamp())}",
                    channel_name=channel,
                    publication_datetime=item.date.isoformat(),
                    post_link=post_link,
                    post_text=post_text,
                    has_media=has_media
                )
                posts.append(post)
                post_count += 1
                
            logger.info(f"‚úÖ snscrape: –Ω–∞–π–¥–µ–Ω–æ {post_count} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –≤ –∫–∞–Ω–∞–ª–µ {channel}")
            return posts
            
        except ImportError as e:
            logger.error(f"‚ùå snscrape –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
            raise
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è snscrape –æ—à–∏–±–∫–∞ –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
            raise
    
    async def _parse_channel_sync(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞ —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π"""
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: HTTP –ø–∞—Ä—Å–∏–Ω–≥
        try:
            return await self._parse_channel_with_http(channel, hours_back, limit)
        except Exception as e:
            logger.warning(f"HTTP –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è {channel}: {e}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: snscrape
        try:
            return self._parse_channel_with_snscrape(channel, hours_back, limit)
        except Exception as e:
            logger.warning(f"snscrape –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è {channel}: {e}")
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: Mock –¥–∞–Ω–Ω—ã–µ
        logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º mock –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}")
        return self._generate_mock_posts(channel, hours_back, limit)
    
    def _generate_mock_posts(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç mock –ø–æ—Å—Ç—ã –¥–ª—è fallback"""
        posts = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ (3-8 –Ω–∞ –∫–∞–Ω–∞–ª)
        num_posts = random.randint(3, min(8, limit))
        
        for i in range(num_posts):
            # –°–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–µ–º—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ø–æ—Å–ª–µ–¥–Ω–∏—Ö hours_back —á–∞—Å–æ–≤
            random_minutes = random.randint(0, hours_back * 60)
            post_time = datetime.now() - timedelta(minutes=random_minutes)
            
            # –°–ª—É—á–∞–π–Ω—ã–π —Ç–µ–∫—Å—Ç
            post_text = random.choice(self.mock_texts)
            
            # –°–ª—É—á–∞–π–Ω–æ–µ –Ω–∞–ª–∏—á–∏–µ –º–µ–¥–∏–∞
            has_media = random.choice([True, False])
            
            post = RawPost(
                id=f"{channel}_mock_{int(post_time.timestamp())}_{i}",
                channel_name=channel,
                publication_datetime=post_time.isoformat(),
                post_link=f"https://t.me/{channel}/{random.randint(1000, 9999)}",
                post_text=post_text,
                has_media=has_media
            )
            posts.append(post)
        
        logger.info(f"üìù –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {num_posts} mock –ø–æ—Å—Ç–æ–≤ –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel}")
        return posts
    
    async def parse_channel(self, channel: str, hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞"""
        return await self._parse_channel_sync(channel, hours_back, limit)
    
    async def parse_channels(self, channels: List[str], hours_back: int = 24, limit: int = 50) -> List[RawPost]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞–Ω–∞–ª–æ–≤"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ {len(channels)} –∫–∞–Ω–∞–ª–æ–≤...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [
            self.parse_channel(channel, hours_back, limit) 
            for channel in channels
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã
        all_posts = []
        successful_channels = 0
        real_posts = 0
        mock_posts = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞–Ω–∞–ª–∞ {channels[i]}: {str(result)}")
                # –î–æ–±–∞–≤–ª—è–µ–º mock –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
                mock_data = self._generate_mock_posts(channels[i], hours_back, limit)
                all_posts.extend(mock_data)
                mock_posts += len(mock_data)
            else:
                all_posts.extend(result)
                successful_channels += 1
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ vs mock –ø–æ—Å—Ç—ã
                for post in result:
                    if "_mock_" in post.id:
                        mock_posts += 1
                    else:
                        real_posts += 1
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        all_posts.sort(
            key=lambda x: datetime.fromisoformat(x.publication_datetime), 
            reverse=True
        )
        
        logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(all_posts)} –ø–æ—Å—Ç–æ–≤ –∏–∑ {len(channels)} –∫–∞–Ω–∞–ª–æ–≤")
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {real_posts} —Ä–µ–∞–ª—å–Ω—ã—Ö, {mock_posts} mock –ø–æ—Å—Ç–æ–≤")
        logger.info(f"üéØ –£—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {successful_channels}/{len(channels)}")
        
        return all_posts
    
    def __del__(self):
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True) 